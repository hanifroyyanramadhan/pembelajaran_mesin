{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cnn-quality-check.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanifroyyanramadhan/praktikum_pembelajaran_mesin/blob/main/cnn_quality_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "* Cacat adalah hal yang tidak diinginkan dalam industri casting. Untuk menghapus produk yang rusak ini, semua industri memiliki departemen inspeksi kualitasnya. \n",
        "* Tapi, masalah utama adalah proses inspeksi ini dilakukan secara manual dan ini adalah proses yang sangat memakan waktu dan karena keterlibatan manusia.\n",
        "* hasil yang diperoleh melalui metode ini tidak 100% akurat. \n",
        "* Ini bisa karena penolakan seluruh pesanan sehingga menciptakan kerugian bagi perusahaan.\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-27T12:59:56.410064Z",
          "iopub.execute_input": "2022-02-27T12:59:56.410358Z",
          "iopub.status.idle": "2022-02-27T12:59:56.41781Z",
          "shell.execute_reply.started": "2022-02-27T12:59:56.410329Z",
          "shell.execute_reply": "2022-02-27T12:59:56.416568Z"
        },
        "id": "rZkw53mosbq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tujuan\n",
        "* Untuk mengotomatiskan proses ini menggunakan model architecture CNN."
      ],
      "metadata": {
        "id": "zllNOOfxsbq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "* Dataset ini adalah casting produk manufaktur.\n",
        "* Casting adalah proses manufaktur di mana bahan cair biasanya dituangkan ke dalam cetakan, yang berisi rongga berongga dari bentuk yang diinginkan, dan kemudian dibiarkan mengeras.\n",
        "* Alasan untuk mengumpulkan data ini adalah cacat casting !!\n",
        "* Cacat pengecoran adalah ketidakteraturan yang tidak diinginkan dalam proses pengecoran logam."
      ],
      "metadata": {
        "id": "KAU1nPBrsbq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n",
        "Seperti biasa, sebelum kita memulai analisis dan pemodelan, mari kita impor beberapa perpustakaan yang diperlukan untuk bekerja dengan data."
      ],
      "metadata": {
        "_uuid": "bbc9f749-7df4-4a4b-82a7-be351fc97643",
        "_cell_guid": "00812653-b593-4f4e-a6fa-0f4190d62f21",
        "trusted": true,
        "id": "w0hHJ-2rsbq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "# Neural Network Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "_uuid": "10e90937-9862-4b5f-9e10-20543cccf967",
        "_cell_guid": "f53ea6ce-b89f-4406-aea8-f142a28f2d33",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:53:56.186574Z",
          "iopub.execute_input": "2022-03-02T08:53:56.187101Z",
          "iopub.status.idle": "2022-03-02T08:54:01.840352Z",
          "shell.execute_reply.started": "2022-03-02T08:53:56.187011Z",
          "shell.execute_reply": "2022-03-02T08:54:01.839577Z"
        },
        "trusted": true,
        "id": "x3e-Pz2Rsbq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Images\n",
        "\n",
        "Berikut adalah struktur folder kami yang berisi data gambar:\n",
        "\n",
        "\n",
        "```\n",
        "casting_data\n",
        "├───test\n",
        "│   ├───def_front\n",
        "│   └───ok_front\n",
        "└───train\n",
        "    ├───def_front\n",
        "    └───ok_front\n",
        "```\n",
        "Folder casting_data terdiri dari dua subfolder test dan train di mana masing-masing memiliki subfolder lain: def_front dan ok_front yang menunjukkan kelas variabel target kami. Gambar di dalam kereta akan digunakan untuk pemasangan model dan validasi, sementara pengujian akan digunakan murni untuk menguji kinerja model pada gambar yang tidak terlihat."
      ],
      "metadata": {
        "_uuid": "6474b603-1f84-4684-8979-70f929daa1da",
        "_cell_guid": "d72a0850-0f63-44cc-a463-3c5decec9758",
        "trusted": true,
        "id": "6v4Sa946sbq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Kami menerapkan augmentasi data on-the-fly, teknik untuk memperluas ukuran dataset pelatihan dengan membuat versi modifikasi dari gambar asli yang dapat meningkatkan kinerja model dan kemampuan untuk menggeneralisasi. Kami akan menggunakan dengan parameter berikut:\n",
        "\n",
        "- `rotation_range`: Rentang derajat untuk rotasi acak. Kami memilih 360 derajat karena produk adalah objek bulat.\n",
        "- `width_shift_range`: Rentang pecahan dari lebar total yang akan digeser.\n",
        "- `height_shift_range`: Rentang fraksi dari total tinggi yang akan digeser.\n",
        "- `shear_range`: Rentang derajat untuk geser acak dalam arah berlawanan arah jarum jam.\n",
        "- `zoom_range`: Rentang pecahan untuk zoom acak.\n",
        "- `horizontal_flip` dan `vertical_flip` diatur ke True untuk membalik gambar secara acak secara horizontal dan vertikal.\n",
        "- `brightness_range`: Rentang pecahan untuk memilih nilai pergeseran kecerahan.\n",
        "\n",
        "Parameter lainnya:\n",
        "\n",
        "- `rescale`: Scala nilai piksel berada di rentang 0 dan 1.\n",
        "- `validation_split`: Reserve 20% of the training data for validation, and the rest 80% for model fitting."
      ],
      "metadata": {
        "_uuid": "9e9ffd65-9682-430c-bdad-fee1cf80707c",
        "_cell_guid": "4eded087-6f3c-4206-90e2-d032ad2fd7fa",
        "trusted": true,
        "id": "xBUFDNfMsbq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(rotation_range = 360,\n",
        "                                     width_shift_range = 0.05,\n",
        "                                     height_shift_range = 0.05,\n",
        "                                     shear_range = 0.05,\n",
        "                                     zoom_range = 0.05,\n",
        "                                     horizontal_flip = True,\n",
        "                                     vertical_flip = True,\n",
        "                                     brightness_range = [0.75, 1.25],\n",
        "                                     rescale = 1./255,\n",
        "                                     validation_split = 0.2)"
      ],
      "metadata": {
        "_uuid": "bd1bd512-554e-461c-a607-6ea5b895ac7a",
        "_cell_guid": "261eefab-d7d7-413c-b46c-c797ceb1d2d5",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:01.841922Z",
          "iopub.execute_input": "2022-03-02T08:54:01.842158Z",
          "iopub.status.idle": "2022-03-02T08:54:01.84799Z",
          "shell.execute_reply.started": "2022-03-02T08:54:01.842124Z",
          "shell.execute_reply": "2022-03-02T08:54:01.847219Z"
        },
        "trusted": true,
        "id": "rJSp_L45sbq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kami menentukan satu set nilai lain untuk parameter 'flow_from_directory':\n",
        "- `IMAGE_DIR`: Direktori tempat data gambar disimpan.\n",
        "- `IMAGE_SIZE`: Dimensi gambar (300 px kali 300 px).\n",
        "- `BATCH_SIZE`: Jumlah gambar yang akan dimuat dan dilatih pada satu waktu.\n",
        "- `SEED_NUMBER`: Pastikan reproduktifitas.\n",
        "- `color_mode = \"grayscale\"`: Perlakukan gambar kami hanya dengan satu warna saluran.\n",
        "- `class_mode` dan `classes` menentukan kelas target dari masalah kita. Dalam hal ini, kami menunjukkan kelas 'cacat' sebagai positif (1), dan 'ok' sebagai kelas negatif.\n",
        "- 'shuffle' = Benar untuk memastikan model mempelajari cacat dan gambar ok secara bergantian."
      ],
      "metadata": {
        "_uuid": "a3f3e0df-63ef-4bb1-a204-35760cfc7c0b",
        "_cell_guid": "6057bdbb-cc2d-4ede-97fb-b67a125f8d9b",
        "trusted": true,
        "id": "SDFyZyETsbrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DIR = \"../input/real-life-industrial-dataset-of-casting-product/casting_data/casting_data/\"\n",
        "IMAGE_SIZE = (300, 300)\n",
        "BATCH_SIZE = 64\n",
        "SEED_NUMBER = 123\n",
        "\n",
        "gen_args = dict(target_size = IMAGE_SIZE,\n",
        "                color_mode = \"grayscale\",\n",
        "                batch_size = BATCH_SIZE,\n",
        "                class_mode = \"binary\",\n",
        "                classes = {\"ok_front\": 0, \"def_front\": 1},\n",
        "                seed = SEED_NUMBER)\n",
        "\n",
        "train_dataset = train_generator.flow_from_directory(\n",
        "                                        directory = IMAGE_DIR + \"train\",\n",
        "                                        subset = \"training\", shuffle = True, **gen_args)\n",
        "validation_dataset = train_generator.flow_from_directory(\n",
        "                                        directory = IMAGE_DIR + \"train\",\n",
        "                                        subset = \"validation\", shuffle = True, **gen_args)"
      ],
      "metadata": {
        "_uuid": "b1b1e9f7-fba7-414d-b644-fc14bf6948e4",
        "_cell_guid": "98242350-740d-4949-9a9a-29259e2a104f",
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:01.849511Z",
          "iopub.execute_input": "2022-03-02T08:54:01.850048Z",
          "iopub.status.idle": "2022-03-02T08:54:09.499565Z",
          "shell.execute_reply.started": "2022-03-02T08:54:01.85001Z",
          "shell.execute_reply": "2022-03-02T08:54:09.498783Z"
        },
        "trusted": true,
        "id": "DQSRNT56sbrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale = 1./255)\n",
        "test_dataset = test_generator.flow_from_directory(directory = IMAGE_DIR + \"test\",\n",
        "                                                  shuffle = False,\n",
        "                                                  **gen_args)"
      ],
      "metadata": {
        "_uuid": "a1e5433d-fa78-4386-a6b0-e6de60fbc187",
        "_cell_guid": "9562f3e7-6ba9-40ad-83c4-10c0633e9e39",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:09.501668Z",
          "iopub.execute_input": "2022-03-02T08:54:09.502103Z",
          "iopub.status.idle": "2022-03-02T08:54:09.710602Z",
          "shell.execute_reply.started": "2022-03-02T08:54:09.502065Z",
          "shell.execute_reply": "2022-03-02T08:54:09.709821Z"
        },
        "trusted": true,
        "id": "VYCp8T78sbrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the Image\n",
        "\n",
        "We successfully load and apply on-the-fly data augmentation according to the specified parameters. Now, in this section, we visualize the image to make sure that it is loaded correctly."
      ],
      "metadata": {
        "_uuid": "16c3953e-ac58-4ce6-979e-b313ad626a50",
        "_cell_guid": "5a0fef8a-bc0c-479d-914e-c8ccbf300717",
        "trusted": true,
        "id": "pKTe_4MXsbrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Image in Batch\n",
        "Visualize the first batch (`BATCH_SIZE = 64`) of the training dataset (images with data augmentation) and also the test dataset (images without data augmentation)."
      ],
      "metadata": {
        "_uuid": "0672f0ca-e2d6-4ba3-b9d8-7cb6846290f5",
        "_cell_guid": "bc53873a-161b-40af-9c77-33035c6aa4df",
        "trusted": true,
        "id": "Ta-Xo70ssbrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_class = {0: \"ok\", 1: \"defect\"}\n",
        "mapping_class"
      ],
      "metadata": {
        "_uuid": "1bc64318-9d61-4e7e-acdf-ab7ee0a5e790",
        "_cell_guid": "cfc30176-35a7-4ad4-a22a-52fa8fa22aec",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:09.711902Z",
          "iopub.execute_input": "2022-03-02T08:54:09.712328Z",
          "iopub.status.idle": "2022-03-02T08:54:09.720433Z",
          "shell.execute_reply.started": "2022-03-02T08:54:09.712267Z",
          "shell.execute_reply": "2022-03-02T08:54:09.719735Z"
        },
        "trusted": true,
        "id": "MrM3TnJksbrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizeImageBatch(dataset, title):\n",
        "    images, labels = next(iter(dataset))\n",
        "    images = images.reshape(BATCH_SIZE, *IMAGE_SIZE)\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(16,16))\n",
        "\n",
        "    for ax, img, label in zip(axes.flat, images, labels):\n",
        "        ax.imshow(img, cmap = \"gray\")\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(mapping_class[label], size = 20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.suptitle(title, size = 30, y = 1.05, fontweight = \"bold\")\n",
        "    plt.show()\n",
        "    \n",
        "    return images"
      ],
      "metadata": {
        "_uuid": "effe4e47-8ce6-43d4-a9c8-b6ab6290a4ab",
        "_cell_guid": "441df6ca-5be2-470d-84b4-62ac58037c6c",
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:09.721758Z",
          "iopub.execute_input": "2022-03-02T08:54:09.722129Z",
          "iopub.status.idle": "2022-03-02T08:54:09.731525Z",
          "shell.execute_reply.started": "2022-03-02T08:54:09.722096Z",
          "shell.execute_reply": "2022-03-02T08:54:09.73074Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "6g3FWBBOsbrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = visualizeImageBatch(train_dataset,\n",
        "                                   \"FIRST BATCH OF THE TRAINING IMAGES\\n(WITH DATA AUGMENTATION)\")"
      ],
      "metadata": {
        "_uuid": "ca46b514-4c97-480e-9bd8-25a9c5630b82",
        "_cell_guid": "7a3c3ada-bf83-424e-8a87-d93e35ffbac7",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:09.732973Z",
          "iopub.execute_input": "2022-03-02T08:54:09.733431Z",
          "iopub.status.idle": "2022-03-02T08:54:16.605061Z",
          "shell.execute_reply.started": "2022-03-02T08:54:09.733396Z",
          "shell.execute_reply": "2022-03-02T08:54:16.60437Z"
        },
        "trusted": true,
        "id": "ALg1Z6y1sbrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = visualizeImageBatch(test_dataset,\n",
        "                                  \"FIRST BATCH OF THE TEST IMAGES\\n(WITHOUT DATA AUGMENTATION)\")"
      ],
      "metadata": {
        "_uuid": "581d8803-5351-4147-8651-9081a0f25e6b",
        "_cell_guid": "3d3b971c-cdd2-4e50-8ff5-27081332b8ad",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:16.60604Z",
          "iopub.execute_input": "2022-03-02T08:54:16.606256Z",
          "iopub.status.idle": "2022-03-02T08:54:22.484745Z",
          "shell.execute_reply.started": "2022-03-02T08:54:16.606227Z",
          "shell.execute_reply": "2022-03-02T08:54:22.484132Z"
        },
        "trusted": true,
        "id": "q6LBQT_psbrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Detailed Image\n",
        "Let's also take a look on the detailed image by each pixel. Instead of plotting 300 pixels by 300 pixels (which computationally expensive), we take a small part of 25 pixels by 25 pixels only"
      ],
      "metadata": {
        "_uuid": "371cea8b-5f39-4201-8790-af54e340e6f2",
        "_cell_guid": "e42c4193-f72b-4c6d-b200-c89f3ba98fcd",
        "trusted": true,
        "id": "SxG9wvu0sbrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.squeeze(train_images[4])[75:100, 75:100]\n",
        "\n",
        "fig = plt.figure(figsize = (15, 15))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img, cmap = \"gray\")\n",
        "ax.axis(\"off\")\n",
        "\n",
        "w, h = img.shape\n",
        "for x in range(w):\n",
        "    for y in range(h):\n",
        "        value = img[x][y]\n",
        "        ax.annotate(\"{:.2f}\".format(value), xy = (y,x),\n",
        "                    horizontalalignment = \"center\",\n",
        "                    verticalalignment = \"center\",\n",
        "                    color = \"white\" if value < 0.4 else \"black\")"
      ],
      "metadata": {
        "_uuid": "e304ca46-fb60-48fd-86c7-9f21d05ec7df",
        "_cell_guid": "a0b42159-4c1c-4875-bdf7-075d940e00ba",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:22.486125Z",
          "iopub.execute_input": "2022-03-02T08:54:22.486818Z",
          "iopub.status.idle": "2022-03-02T08:54:26.26873Z",
          "shell.execute_reply.started": "2022-03-02T08:54:22.486781Z",
          "shell.execute_reply": "2022-03-02T08:54:26.26812Z"
        },
        "trusted": true,
        "id": "2Ok8bdzusbrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the example of values that we are going to feed into our CNN architecture."
      ],
      "metadata": {
        "_uuid": "9640f7d5-5df8-46d9-a573-983a95dfaccd",
        "_cell_guid": "fcb347ab-9dcd-456d-9af3-fe088df2c42a",
        "trusted": true,
        "id": "KAazINxcsbrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Network\n",
        "\n",
        "As mentioned earlier, we are going to train a CNN model to classify the casting product image. CNN is used as an automatic feature extractor from the images so that it can learn how to distinguish between `defect` and `ok` casted products. It effectively uses the adjacent pixel to downsample the image and then use a prediction (fully-connected) layer to solve the classification problem. This is a simple illustration by [Udacity](https://github.com/udacity/deep-learning-v2-pytorch) on how the layers are arranged sequentially:\n",
        "\n",
        "![](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/convolutional-neural-networks/conv-visualization/notebook_ims/CNN_all_layers.png)"
      ],
      "metadata": {
        "_uuid": "6f056666-5c7f-44cc-802a-fea462c05f7c",
        "_cell_guid": "ef9fd6eb-882f-413b-9df8-df873cc95901",
        "trusted": true,
        "id": "m94AkFoWsbrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Architecture\n",
        "\n",
        "Here is the detailed architecture that we are going to use:\n",
        "\n",
        "1. **First convolutional layer**: consists of 32 filters with kernel_size matrix 3 by 3. Using 2-pixel strides at a time, reduce the image size by half.\n",
        "2. **First pooling layer**: Using max-pooling matrix 2 by 2 (pool_size) and 2-pixel strides at a time further reduce the image size by half.\n",
        "3. **Second convolutional layer**: Just like the first convolutional layer but with 16 filters only.\n",
        "4. **Second pooling layer**: Same as the first pooling layer.\n",
        "5. **Flattening**: Convert two-dimensional pixel values into one dimension, so that it is ready to be fed into the fully-connected layer.\n",
        "6. **First dense layer + Dropout**: consists of 128 units and 1 bias unit. Dropout of rate 20% is used to prevent overfitting.\n",
        "7. **Second dense layer + Dropout**: consists of 64 units and 1 bias unit. Dropout of rate 20% is also used to prevent overfitting.\n",
        "8. **Output layer**: consists of only one unit and activation is a sigmoid function to convert the scores into a probability of an image being defect.\n",
        "\n",
        "For every layer except output layer, we use Rectified Linear Unit (ReLU) activation function.\n",
        "\n",
        "![relu](https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/convolutional-neural-networks/conv-visualization/notebook_ims/relu_ex.png)"
      ],
      "metadata": {
        "_uuid": "e773159a-6b4e-49db-9698-015f82f585dd",
        "_cell_guid": "b995fbac-f40e-48fb-a62a-19b2261b6a10",
        "trusted": true,
        "id": "E605cR9hsbrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Sequential(\n",
        "    [\n",
        "        # First convolutional layer\n",
        "        Conv2D(filters = 32,\n",
        "               kernel_size = 3,\n",
        "               strides = 2,\n",
        "               activation = \"relu\",\n",
        "               input_shape = IMAGE_SIZE + (1, )),\n",
        "        \n",
        "        # First pooling layer\n",
        "        MaxPooling2D(pool_size = 2,\n",
        "                     strides = 2),\n",
        "        \n",
        "        # Second convolutional layer\n",
        "        Conv2D(filters = 16,\n",
        "               kernel_size = 3,\n",
        "               strides = 2,\n",
        "               activation = \"relu\"),\n",
        "        \n",
        "        # Second pooling layer\n",
        "        MaxPooling2D(pool_size = 2,\n",
        "                     strides = 2),\n",
        "        \n",
        "        # Flattening\n",
        "        Flatten(),\n",
        "        \n",
        "        # Fully-connected layer\n",
        "        Dense(128, activation = \"relu\"),\n",
        "        Dropout(rate = 0.2),\n",
        "        \n",
        "        Dense(64, activation = \"relu\"),\n",
        "        Dropout(rate = 0.2),\n",
        "        \n",
        "        Dense(1, activation = \"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_cnn.summary()"
      ],
      "metadata": {
        "_uuid": "af76de8e-4fec-4037-870b-3143cf71a09b",
        "_cell_guid": "7a7c1892-86ba-4bd8-8891-955e0a7f0552",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:26.271264Z",
          "iopub.execute_input": "2022-03-02T08:54:26.271964Z",
          "iopub.status.idle": "2022-03-02T08:54:28.609693Z",
          "shell.execute_reply.started": "2022-03-02T08:54:26.271926Z",
          "shell.execute_reply": "2022-03-02T08:54:28.608963Z"
        },
        "trusted": true,
        "id": "_zg88cHPsbrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the Model\n",
        "\n",
        "Next, we specify how the model backpropagates or update the weights after each batch feed-forward. We use `adam` optimizer and a loss function `binary cross-entropy` since we are dealing with binary classification problem. The metrics used to monitor the training progress is accuracy."
      ],
      "metadata": {
        "_uuid": "8089a10b-296f-4c3a-8e83-079c99a7597f",
        "_cell_guid": "4edfccc9-6107-4af7-9e01-c91192ca59a3",
        "trusted": true,
        "id": "iagnrjTksbrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "_uuid": "74a5620a-6ed8-4b46-90e7-75bdef709eb0",
        "_cell_guid": "35d7a24b-0081-4744-acf8-3e219915af71",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:28.610854Z",
          "iopub.execute_input": "2022-03-02T08:54:28.611284Z",
          "iopub.status.idle": "2022-03-02T08:54:28.625419Z",
          "shell.execute_reply.started": "2022-03-02T08:54:28.611243Z",
          "shell.execute_reply": "2022-03-02T08:54:28.624733Z"
        },
        "trusted": true,
        "id": "yu6la3l1sbrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fitting¶\n",
        "Before we do model fitting, let's check whether GPU is available or not."
      ],
      "metadata": {
        "_uuid": "bf95096d-463e-497c-9f72-e295ecd42934",
        "_cell_guid": "899072d6-e95e-4343-821d-7d79d736f89e",
        "trusted": true,
        "id": "t8RGFPrRsbrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('model/cnn_casting_inspection_model.hdf5',\n",
        "                             verbose = 1,\n",
        "                             save_best_only = True,\n",
        "                             monitor='val_loss',\n",
        "                             mode='min')\n",
        "\n",
        "model_cnn.fit(train_dataset,\n",
        "                    validation_data = validation_dataset,\n",
        "                    batch_size = 16, \n",
        "                    epochs = 15,\n",
        "                    callbacks = [checkpoint],\n",
        "                    verbose = 1)"
      ],
      "metadata": {
        "_uuid": "cd3b0d0d-d832-46c8-9a37-ea4447cf5cb8",
        "_cell_guid": "3160af8e-f2f9-4643-98f7-f6ff689e2e26",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T08:54:28.626539Z",
          "iopub.execute_input": "2022-03-02T08:54:28.626825Z",
          "iopub.status.idle": "2022-03-02T09:09:53.855461Z",
          "shell.execute_reply.started": "2022-03-02T08:54:28.626766Z",
          "shell.execute_reply": "2022-03-02T09:09:53.85364Z"
        },
        "trusted": true,
        "id": "54IFmQf3sbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Evaluation\n",
        "Let's plot both loss and accuracy metrics for train and validation data based on each epoch."
      ],
      "metadata": {
        "_uuid": "f059de1b-de46-4223-8a7e-eaf566906502",
        "_cell_guid": "86150375-11a4-4162-b0ba-7eb76b5e573e",
        "trusted": true,
        "id": "64DfnaSvsbrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize = (8, 6))\n",
        "sns.lineplot(data = pd.DataFrame(model_cnn.history.history,\n",
        "                                 index = range(1, 1+len(model_cnn.history.epoch))))\n",
        "plt.title(\"TRAINING EVALUATION\", fontweight = \"bold\", fontsize = 20)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Metrics\")\n",
        "\n",
        "plt.legend(labels = ['val loss', 'val accuracy', 'train loss', 'train accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "6002c74c-f89e-49ef-9c91-906ee7f81481",
        "_cell_guid": "a61e8ae9-67dc-4368-8446-b5b0f1bd09ae",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T09:09:53.858746Z",
          "iopub.execute_input": "2022-03-02T09:09:53.859078Z",
          "iopub.status.idle": "2022-03-02T09:09:54.24735Z",
          "shell.execute_reply.started": "2022-03-02T09:09:53.859039Z",
          "shell.execute_reply": "2022-03-02T09:09:54.246619Z"
        },
        "trusted": true,
        "id": "vrKI--JdsbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that the model is **not overfitting** the data since both train loss and val loss simultaneously dropped towards zero. Also, both train accuracy and val accuracy increase towards 100%."
      ],
      "metadata": {
        "_uuid": "339c75bf-019a-43ae-8329-64a00093ed02",
        "_cell_guid": "3762a585-b6c9-4934-afd1-b9333e88c7d5",
        "trusted": true,
        "id": "ChZd1V7OsbrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on Unseen Images\n",
        "\n",
        "Our model performs very well on the training and validation dataset which uses augmented images. Now, we test our model performance with unseen and unaugmented images."
      ],
      "metadata": {
        "_uuid": "323f83c0-749f-4aca-be47-fcb933b97ad6",
        "_cell_guid": "a12909fb-aa92-4f7c-ac2b-d9c25274cfa5",
        "trusted": true,
        "id": "0CLq_ctSsbrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(\"model/cnn_casting_inspection_model.hdf5\")"
      ],
      "metadata": {
        "_uuid": "0352df0a-f22f-4a89-8460-f072407096bc",
        "_cell_guid": "505db812-0cde-4626-9579-dcafdd9a2184",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T09:09:54.248633Z",
          "iopub.execute_input": "2022-03-02T09:09:54.249052Z",
          "iopub.status.idle": "2022-03-02T09:09:54.402378Z",
          "shell.execute_reply.started": "2022-03-02T09:09:54.249018Z",
          "shell.execute_reply": "2022-03-02T09:09:54.401616Z"
        },
        "trusted": true,
        "id": "erI2AXy_sbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = best_model.predict(test_dataset)"
      ],
      "metadata": {
        "_uuid": "79e714d1-5a9a-4388-8ef0-7e0c9f350840",
        "_cell_guid": "04d9cba5-c641-42fe-936d-28d957c13348",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T09:09:54.403778Z",
          "iopub.execute_input": "2022-03-02T09:09:54.404225Z",
          "iopub.status.idle": "2022-03-02T09:10:00.36654Z",
          "shell.execute_reply.started": "2022-03-02T09:09:54.404192Z",
          "shell.execute_reply": "2022-03-02T09:10:00.365779Z"
        },
        "trusted": true,
        "id": "FSlDp4vlsbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the prediction is in the form of probability. We use THRESHOLD = 0.5 to separate the classes. If the probability is greater or equal to the THRESHOLD, then it will be classified as defect, otherwise ok."
      ],
      "metadata": {
        "_uuid": "d51025ab-e50c-4fd2-b126-fdb8907f88e0",
        "_cell_guid": "70b1b519-54a7-47cf-9b29-b79fb82cf167",
        "trusted": true,
        "id": "tvhjCMKIsbrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.5\n",
        "y_pred_class = (y_pred_prob >= THRESHOLD).reshape(-1,)\n",
        "y_true_class = test_dataset.classes[test_dataset.index_array]\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(y_true_class, y_pred_class),\n",
        "    index = [[\"Actual\", \"Actual\"], [\"ok\", \"defect\"]],\n",
        "    columns = [[\"Predicted\", \"Predicted\"], [\"ok\", \"defect\"]],\n",
        ")"
      ],
      "metadata": {
        "_uuid": "edc0376b-0827-4aa1-96d8-c6bc928398d1",
        "_cell_guid": "003e81ce-9dbb-4e3a-ae97-8199515eca79",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T09:10:00.368124Z",
          "iopub.execute_input": "2022-03-02T09:10:00.368617Z",
          "iopub.status.idle": "2022-03-02T09:10:00.393897Z",
          "shell.execute_reply.started": "2022-03-02T09:10:00.368579Z",
          "shell.execute_reply": "2022-03-02T09:10:00.393236Z"
        },
        "trusted": true,
        "id": "U6K9vW_asbrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true_class, y_pred_class, digits = 4))"
      ],
      "metadata": {
        "_uuid": "82bf4054-718e-4b01-b289-8fe47e5ee9d9",
        "_cell_guid": "3111d5b5-c0ed-47ea-b48c-662774deaedb",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-03-02T09:10:00.3952Z",
          "iopub.execute_input": "2022-03-02T09:10:00.395646Z",
          "iopub.status.idle": "2022-03-02T09:10:00.409028Z",
          "shell.execute_reply.started": "2022-03-02T09:10:00.395611Z",
          "shell.execute_reply": "2022-03-02T09:10:00.408349Z"
        },
        "trusted": true,
        "id": "lv6QhRBrsbrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the problem statement, we want to minimize the case of False Negative, where the defect product is misclassified as `ok`. This can cause the whole order to be rejected and create a big loss for the company. Therefore, in this case, we prioritize Recall over Precision.\n",
        "\n",
        "But if we take into account the cost of re-casting a product, we have to minimize the case of False Positive also, where the ok product is misclassified as `defect`. Therefore we can prioritize the `F1 score` which combines both Recall and Precision.\n",
        "\n",
        "On test dataset, the model achieves a very good result as follow:\n",
        "\n",
        "- Accuracy: 99.02 %\n",
        "- Recall: 99.12%\n",
        "- Precision: 99.34%\n",
        "- F1 score 99.23%%"
      ],
      "metadata": {
        "_uuid": "a5d77dc4-e424-4944-8296-dd21cf575c5f",
        "_cell_guid": "c06aaf97-f862-4e62-80e3-e91e09dad363",
        "trusted": true,
        "id": "atpxLbpvsbrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "# Conclusion\n",
        "By using CNN and on-the-fly data augmentation, the performance of our model in training, validation, and test images is almost perfect, reaching 98-99% accuracy and F1 score. We can utilize this model by embedding it into a surveillance camera where the system can automatically separate defective product from the production line. This method surely can reduce human error and human resources on manual inspection, but it still needs supervision from human since the model is not 100% correct at all times."
      ],
      "metadata": {
        "_uuid": "9561d0ca-bbf4-463a-8c61-5e72de6359bd",
        "_cell_guid": "398d9588-5f03-42ce-95c7-529d10c0a1dc",
        "trusted": true,
        "id": "bsdHwfiXsbrG"
      }
    }
  ]
}